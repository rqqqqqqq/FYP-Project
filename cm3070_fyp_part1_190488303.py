# -*- coding: utf-8 -*-
"""CM3070_FYP_Part1_190488303.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Zoa4GIBO3nevyQk-q_sHD4_5rHwysQ_

# CM3070 Final Year Project: Bitcoin Price Forecasting - PART 1

Template 1: Deep Learning on a Public Dataset (Machine Learning)		
Done by Student Number: 190488303

## Project Deliverables

1. Introduction 
  
        1.1 Aims and objectives

2. Import data, libraries and packages
3. Exploratory data analysis - EDA
4. Data preparation

        4.1 Data cleaning
        4.2 Data splitting
        4.3 Pre-processing

5. Modelling
    
      5.1 Baseline (Support vector regression (SVR))
          5.1.1 Modelling
          5.1.2 Prediction
          5.1.3 MAE, MSE, RMSE 
          5.1.4 Explained variance regression score, R2 score  

      5.2 XGBoost 
          5.2.1 Modelling
          5.2.2 Prediction
          5.2.3 MAE, MSE, RMSE 
          5.2.4 Explained variance regression score, R2 score  

      5.3 Long Short Term Memory (LSTM)
          5.3.1 Modelling
          5.3.2 Prediction
          5.3.3 MAE, MSE, RMSE 
          5.3.4 Explained variance regression score, R2 score  

      5.4 Linear regression
          5.4.1 Modelling
          5.4.2 Prediction
          5.4.3 MAE, MSE, RMSE 
          5.4.4 Explained variance regression score, R2 score  

      5.5 ARIMA model
          5.5.1 Modelling
          5.5.2 Prediction
          5.5.3 MAE, MSE, RMSE 
          5.5.4 Explained variance regression score, R2 score  

6. Conclusion

## 1. Introduction

This project conceptualizes the idea of using a machine learning model for bitcoin price forecasting. The aim is to see if it is possible to predict the future price of bitcoin, and if so, how to increase its efficiency by using different machine learning models.

The objective for this project is to increase competitiveness when buying or selling bitcoin, in order to make more money. If successful, it can be used from a personal standpoint, for casual bitcoin buyers to make more informed decisions when timing the cryptocurrency market such that they can make more profitable purchases. It can also be adopted from a commercial standpoint, where brokerage firms or financial advisors can implement the methodology to make more informed financial decisions for their clients when buying bitcoin, thus increasing their credibility and success as a service. 


The aim of this project is to explore the potential use of different models for the purpose of bitcoin price predication, or more specifically, the LSTM model. The project would include data preparation, the creation of baseline models as performance evaluators, and the creation of LSTM forecasting model.

## 2. Import data, libraries and packages

This project uses project template 1, which is deep learning on a public dataset, adapted from Kaggle. Kaggle is open-source and community maintained, making it ethically appropriate to be used for this project. The data shows one-minute intervals from select exchanges from January 2012 to March 2021. The timestamps are in Unix time, and it contains minute updates of OLCH prices (Open, High, Low, Close). [5]
"""

from google.colab import drive
drive.mount('/content/drive')

ls drive/MyDrive/bitcoin_data.csv

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from datetime import datetime
import gc
import plotly.graph_objs as go

from sklearn.model_selection import TimeSeriesSplit
from sklearn.model_selection import train_test_split

from plotly import tools
from plotly.offline import init_notebook_mode, iplot
init_notebook_mode(connected=True)

# create funcion to render and plot graph

def plot_function():
  import IPython
  from plotly.offline import init_notebook_mode
  display(IPython.core.display.HTML('''<script src="/static/components/requirejs/require.js"></script>'''))
  init_notebook_mode(connected=False)

#create a function for conversion for the native timestamps in the csv file

import datetime, pytz

def dateparse (time_in_secs):    
    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))

bitcoin_df = pd.read_csv("drive/MyDrive/bitcoin_data.csv", parse_dates = [0], date_parser = dateparse)
bitcoin_df.head()

"""## 3. Exploratory data analysis - EDA"""

# fill data that have no trades

bitcoin_df['Open'].fillna(method='ffill', inplace=True)
bitcoin_df['Low'].fillna(method='ffill', inplace=True)
bitcoin_df['Close'].fillna(method='ffill', inplace=True)
bitcoin_df['High'].fillna(method='ffill', inplace=True)

bitcoin_df['Weighted_Price'].fillna(method='ffill', inplace=True)
bitcoin_df['Volume_(Currency)'].fillna(method='ffill', inplace=True)
bitcoin_df['Volume_(BTC)'].fillna(method='ffill', inplace=True)

bitcoin_df = bitcoin_df.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()

print('Amount of null values:',bitcoin_df.isnull().values.sum())

bitcoin_df.head()

# creating plots with plotly https://plot.ly/python/

plot_function()

trace1 = go.Scatter(
    x = bitcoin_df['Timestamp'],
    y = bitcoin_df['Open'].astype(float),
    mode = 'lines',
    name = 'Open'
)

trace3 = go.Scatter(
    x = bitcoin_df['Timestamp'],
    y = bitcoin_df['Weighted_Price'].astype(float),
    mode = 'lines',
    name = 'Weighted Avg'
)

trace2 = go.Scatter(
    x = bitcoin_df['Timestamp'],
    y = bitcoin_df['Close'].astype(float),
    mode = 'lines',
    name = 'Close'
)

layout = dict(
    title='Bitcoin Prices from 2012 to 2021 (With slider function) ',
    xaxis=dict(
        rangeselector=dict(
            buttons=list([
                
                # count corresponds to no of months
                dict(count=1,
                     label='1m',
                     step='month',
                     stepmode='backward'),

                dict(count=3,
                     label='3m',
                     step='month',
                     stepmode='backward'),

                dict(count=12,
                     label='1y',
                     step='month',
                     stepmode='backward'),

                dict(count=72,
                     label='6y',
                     step='month',
                     stepmode='backward'),

                dict(step='all')
            ])
        ),
        rangeslider=dict(
            visible = True
        ),
        type='date'
    )
)
data = [trace1, trace2, trace3]
fig = dict(data = data, layout = layout)

iplot(fig, filename = "Time Series with Rangeslider")

"""## 4. Data Preparation

4.1 Data cleaning
"""

# using hourly data
bitcoin_df = bitcoin_df.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()

# setting timestamp as index
bitcoin_df['Timestamp'] = bitcoin_df['Timestamp'].dt.tz_localize(None)
bitcoin_df = bitcoin_df.set_index('Timestamp')

# using weighted price to represent btc price
bitcoin_df = bitcoin_df[['Weighted_Price']]

# fill null values with previous data
bitcoin_df['Weighted_Price'].fillna(method='ffill', inplace=True)
bitcoin_df.head()

# using data from pre-covid era

day_of_split = '1-Nov-2020'
new_df = bitcoin_df.loc[bitcoin_df.index < day_of_split].copy()

print(new_df.shape)

new_df.tail()

"""4.2 Data Splitting"""

# splitting data into training and test sets
day_of_split = '25-Jun-2018'

testing_data = new_df.loc[new_df.index > day_of_split].copy()
training_data = new_df.loc[new_df.index <= day_of_split].copy()

print(testing_data.shape)
print(training_data.shape)

""" 4.3 Pre-processing"""

# data preprocessing
set_train_val = training_data.values
set_train_val = np.reshape(set_train_val, (len(set_train_val), 1))

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
set_train_val = mms.fit_transform(set_train_val)
y_train = set_train_val[1: len(set_train_val)]
X_train = set_train_val[0: len(set_train_val)-1]

print(X_train.shape)
print(y_train.shape)

# visualising training and test data
_ = testing_data \
    .rename(columns={'Weighted_Price': 'Data for Test Set'}) \
    .join(training_data.rename(columns = {'Weighted_Price': 'Data for Training Set'}), how = 'outer') \
    .plot(figsize=(21,7), title = 'Weighted Price of Bitcoin (USD) by Minutes', style='')

"""## 5. Modelling

### 5.1 Baseline model (Support vector regression)

5.1.1 Modelling
"""

# import Keras package and libraries

from sklearn.svm import SVR

svr_rbf_model = SVR(kernel = 'rbf', C = 1e3, gamma = 0.0001)
svr_rbf_model.fit(X_train, y_train.ravel())

"""5.1.2 Prediction"""

# forming predictions

set_test_val = testing_data.values

insert = np.reshape(set_test_val, (len(set_test_val), 1))
insert = mms.transform(insert)
insert = np.reshape(insert, (len(insert), 1))

btc_price_prediction = svr_rbf_model.predict(insert)
btc_price_prediction = btc_price_prediction.reshape(1, -1)
btc_price_prediction = mms.inverse_transform(btc_price_prediction)
btc_price_prediction = btc_price_prediction.reshape(-1, 1)

btc_price_prediction

testing_data['Weighted_Price_Prediction'] = btc_price_prediction
data_all = pd.concat([testing_data, training_data], sort=False)

# store predicted values into common dataframe 
df_last = data_all
df_last = df_last.reset_index()
df_last = df_last.rename(columns = {'Weighted_Price_Prediction': 'SVR'})
df_last = df_last[['Timestamp','Weighted_Price','SVR']]
df_last.head()

_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize = (21, 7))

"""5.1.3 Evaluation metrics (MAE, MSE, RMSE)"""

from sklearn.metrics import mean_squared_error, mean_absolute_error

mae = mean_absolute_error(y_true = testing_data['Weighted_Price'], y_pred = testing_data['Weighted_Price_Prediction'])

print("Mean Accuracy Error:\n")
print(mae)

mse = mean_squared_error(y_true = testing_data['Weighted_Price'], y_pred = testing_data['Weighted_Price_Prediction'])

print("Mean Square Error:\n")
print(mse)

import math
rmse = math.sqrt(mse)

print("Root Mean Square Error:\n")
print(rmse)

"""5.1.4 Evaluation metrics (Variance regression score, R2 score)"""

from sklearn.metrics import explained_variance_score
evr = (explained_variance_score(y_true = testing_data['Weighted_Price'], y_pred = testing_data['Weighted_Price_Prediction']))*100

print("Explained variance regression score:", evr, "%")

from sklearn.metrics import r2_score
r2 = (r2_score(y_true = testing_data['Weighted_Price'], y_pred = testing_data['Weighted_Price_Prediction']))*100

print("R2 score:", r2, "%")

"""### 5.2 XGBoost

5.2.1 Modelling
"""

def timeseries_feature(bitcoin_df, label=None):

    """
    Using c
    """
    bitcoin_df['Date'] = bitcoin_df.index
    bitcoin_df['Week_of_year'] = bitcoin_df['Date'].dt.weekofyear
    bitcoin_df['Day_of_week'] = bitcoin_df['Date'].dt.dayofweek
    bitcoin_df['Year'] = bitcoin_df['Date'].dt.year
    bitcoin_df['Day_of_year'] = bitcoin_df['Date'].dt.dayofyear
    bitcoin_df['Quarter'] = bitcoin_df['Date'].dt.quarter
    bitcoin_df['Hour'] = bitcoin_df['Date'].dt.hour
    bitcoin_df['Day_of_month'] = bitcoin_df['Date'].dt.day
    bitcoin_df['Month'] = bitcoin_df['Date'].dt.month
    
    X = bitcoin_df[['Hour','Day_of_week','Quarter','Month','Year',
           'Day_of_year','Day_of_month','Week_of_year']]

    if label:
        y = bitcoin_df[label]
        return X, y
    return X

X_test, y_test = timeseries_feature(testing_data, label='Weighted_Price')
X_train, y_train = timeseries_feature(training_data, label='Weighted_Price')

import xgboost as xgb
from xgboost import plot_importance, plot_tree

xgb_model =  xgb.XGBRegressor(objective = 'reg:linear', min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1,
                max_depth = 5, alpha = 10, n_estimators = 100)

history = xgb_model.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_test, y_test)],
        early_stopping_rounds=50, verbose = True)

"""5.2.2 Prediction"""

testing_data['Weighted_Price_Prediction'] = xgb_model.predict(X_test)
data_all = pd.concat([testing_data, training_data], sort=False)

#saving the predicted values in a common data frame for future comparision
df_last = pd.merge(df_last, data_all, sort=False)
df_last = df_last.rename(columns = {'Weighted_Price_Prediction': 'XGBoost'})
df_last = df_last[['Timestamp','Weighted_Price','SVR','XGBoost']]
df_last.head()

_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(21, 7))

"""5.2.3 Evaluation metrics (MAE, MSE, RMSE)"""

from sklearn.metrics import mean_squared_error, mean_absolute_error

mae = mean_absolute_error(y_true=testing_data['Weighted_Price'],
                   y_pred=testing_data['Weighted_Price_Prediction'])

print("Mean Accuracy Error:\n")
print(mae)

mse = mean_squared_error(y_true=testing_data['Weighted_Price'],
                   y_pred=testing_data['Weighted_Price_Prediction'])

print("Mean Square Error:\n")
print(mse)

import math
rmse = math.sqrt(mse)

print("Root Mean Square Error:\n")
print(rmse)

"""5.2.4 Evaluation metrics (Variance regression score, R2 score)"""

from sklearn.metrics import explained_variance_score
evr = (explained_variance_score(y_true=testing_data['Weighted_Price'], y_pred=testing_data['Weighted_Price_Prediction']))*100

print("Explained variance regression score:", evr, "%")

from sklearn.metrics import r2_score
r2 = (r2_score(y_true=testing_data['Weighted_Price'], y_pred=testing_data['Weighted_Price_Prediction']))*100

print("R2 score:", r2, "%")

"""### 5.3 Long short term memory (LSTM)

5.3.1 Modelling
"""

# splitting data into training and test sets
day_of_split = '25-Jun-2018'

testing_data = new_df.loc[new_df.index > day_of_split].copy()
training_data = new_df.loc[new_df.index <= day_of_split].copy()

print(testing_data.shape)
print(training_data.shape)

# data preprocessing
set_train_val = training_data.values
set_train_val = np.reshape(set_train_val, (len(set_train_val), 1))

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
set_train_val = mms.fit_transform(set_train_val)
y_train = set_train_val[1: len(set_train_val)]
X_train = set_train_val[0: len(set_train_val)-1]

print(X_train.shape)
print(y_train.shape)

# import the Keras packages and libraries

from keras.models import Sequential
from keras.layers import Dropout
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Activation

lstm_model = Sequential()

# adding layers
lstm_model.add(LSTM(128,activation = "sigmoid", input_shape = (1,1), return_sequences = True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=50, return_sequences = True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(units=50, return_sequences = True))
lstm_model.add(LSTM(units=50, return_sequences = True))
lstm_model.add(LSTM(units=50, return_sequences = True))
lstm_model.add(Activation('linear'))
lstm_model.add(LSTM(units=50))
lstm_model.add(Dense(1))


lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
history = lstm_model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=1, validation_split = 0.05)

epoch = range(1,101)

training_loss = history.history['loss']
validation_loss = history.history['val_loss']

plt.plot(epoch, validation_loss, 'b', label='Validation loss')
plt.plot(epoch, training_loss, 'g', label='Training loss')

plt.title('Training and Validation set loss')
plt.ylabel('Loss')
plt.xlabel('Number of epochs')
plt.legend()
plt.show()

epoch = range(1,101)

training_loss = history.history['accuracy']
validation_loss = history.history['val_accuracy']

plt.plot(epoch, validation_loss, 'b', label='Validation accuracy')
plt.plot(epoch, training_loss, 'g', label='Training accuracy')


plt.title('Training and Validation set accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Number of epochs')
plt.legend()
plt.show()

"""4.3.2 Prediction"""

# making predictions

set_test_val = testing_data.values

insert = np.reshape(set_test_val, (len(set_test_val), 1))
insert = mms.transform(insert)
insert = np.reshape(insert, (len(insert), 1))

btc_price_prediction = svr_rbf_model.predict(insert)
btc_price_prediction = btc_price_prediction.reshape(1, -1)
btc_price_prediction = mms.inverse_transform(btc_price_prediction)
btc_price_prediction = btc_price_prediction.reshape(-1, 1)

btc_price_prediction

testing_data['Weighted_Price_Prediction'] = btc_price_prediction
data_all = pd.concat([testing_data, training_data], sort=False)

#saving the predicted values in a common data frame for future comparision
df_last = pd.merge(df_last, data_all, sort=False)
df_last = df_last.rename(columns = {'Weighted_Price_Prediction': 'LSTM'})
df_last = df_last[['Timestamp','Weighted_Price','SVR','XGBoost', 'LSTM']]
df_last.head()

_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(21, 7))

"""5.3.2 Evaluation metrics (MAE, MSE, RMSE)"""

from sklearn.metrics import mean_squared_error, mean_absolute_error

mae = mean_absolute_error(y_true=testing_data['Weighted_Price'],
                   y_pred=testing_data['Weighted_Price_Prediction'])

print("Mean Accuracy Error:\n")
print(mae)

mse = mean_squared_error(y_true=testing_data['Weighted_Price'],
                   y_pred=testing_data['Weighted_Price_Prediction'])

print("Mean Square Error:\n")
print(mse)

import math
rmse = math.sqrt(mse)

print("Root Mean Square Error:\n")
print(rmse)

"""5.3.3 Evaluation metrics (Variance regression score, R2 score)"""

from sklearn.metrics import explained_variance_score
evr = (explained_variance_score(y_true=testing_data['Weighted_Price'], y_pred=testing_data['Weighted_Price_Prediction']))*100

print("Explained variance regression score:", evr, "%")

from sklearn.metrics import r2_score
r2 = (r2_score(y_true=testing_data['Weighted_Price'], y_pred=testing_data['Weighted_Price_Prediction']))*100

print("R2 score:", r2, "%")